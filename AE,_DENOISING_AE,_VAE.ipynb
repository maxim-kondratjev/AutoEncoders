{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AE, DENOISING AE, VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IupxoPKiex16",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "  \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import torch.nn.init\n",
        "import torchvision.datasets as dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import FloatTensor\n",
        "import matplotlib.pylab as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KBBS6KxwVqHw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
        "plt.rcParams[\"axes.grid\"] = False\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IrXIltGoex2L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "root = './data'\n",
        "\n",
        "train_set = dataset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_set = dataset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=train_set,\n",
        "                 batch_size=32,\n",
        "                 shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                dataset=test_set,\n",
        "                batch_size=32,\n",
        "                shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QwMfDGDex21",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_noise(img):\n",
        "    noise = torch.randn(img.size()) * 0.5\n",
        "    noisy_img = img + noise.cuda()\n",
        "    return noisy_img\n",
        "    \n",
        "def compute_one(model, n, noise=False):\n",
        "    x = train_set[n][0]\n",
        "    if noise:\n",
        "      x = add_noise(x.cuda())\n",
        "      \n",
        "    x = x.view(1, 1, 28, 28).cpu().cuda()\n",
        "    y = model(x)\n",
        "    \n",
        "    if type(y) == tuple:\n",
        "      y = y[0]\n",
        "\n",
        "    f,ax = plt.subplots(1, 2)\n",
        "\n",
        "    ax[0].imshow(x[0].cpu().data.numpy().reshape((28,28)), interpolation=\"nearest\")\n",
        "    ax[1].imshow(y.cpu().data.numpy()[0,0], interpolation=\"nearest\")\n",
        "    plt.show()\n",
        "    \n",
        "def compute_random(model, n, noise=False):\n",
        "    for i in np.random.randint(0, len(train_set), n):\n",
        "        compute_one(model, i, noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxFvYu0tgtkD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Обычный автоэнкодер"
      ]
    },
    {
      "metadata": {
        "id": "xjTZHyNIex2Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 26, 5, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            \n",
        "            nn.Conv2d(26, 36, 5, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        \n",
        "            nn.Conv2d(36, 64, 3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        \n",
        "        self.in_linear = nn.Linear(64, 4)\n",
        "        self.out_linear = nn.Linear(4, 64)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 36, 3, 1),\n",
        "            \n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(36, 26, 5, 1),\n",
        "            \n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(26, 1, 5, 1),\n",
        "        )\n",
        "        \n",
        "        self.initialize()\n",
        "        \n",
        "    def initialize(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data = nn.init.xavier_uniform_(m.weight)\n",
        "                \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(-1, 64)\n",
        "        x = self.in_linear(x)\n",
        "        \n",
        "        self.embeding = x\n",
        "        \n",
        "        x = self.out_linear(x)\n",
        "        x = x.view(-1, 64, 1, 1)\n",
        "        x = self.decoder(x)\n",
        "        \n",
        "        return x\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yvSMtUUigBnD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = Autoencoder()\n",
        "net.cuda()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "loss_acc = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "YrKnoPKuex2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for ep in range(3):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        y = net(data)\n",
        "\n",
        "        loss = criterion(y, data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_acc.append(loss.data[0])\n",
        "        \n",
        "    print('Epoch: ', ep, ', loss: ', float(loss.data[0]), sep='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A34NkYKWUBPP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "compute_random(net, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnmqTl-dex3B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_intermediate_states(model, n1, n2, states):\n",
        "    x1 = train_set[n1][0].cuda()\n",
        "    x1 = x1.view(1, 1, 28, 28).cpu().cuda()\n",
        "    y1 = model(x1)\n",
        "\n",
        "    emb = [model.embeding]\n",
        "\n",
        "    x2 = train_set[n2][0].cpu().cuda()\n",
        "    x2 = x2.view(1, 1, 28, 28)\n",
        "    y2 = model(x2)\n",
        "\n",
        "    emb.append(model.embeding)\n",
        "    \n",
        "    delta = emb[0] - emb[1]\n",
        "    \n",
        "    f,ax = plt.subplots(1, states+2)\n",
        "    \n",
        "    ax[0].imshow(x2[0].cpu().data.numpy().reshape((28,28)), interpolation=\"nearest\")\n",
        "    \n",
        "    for i in range(states):\n",
        "        state = (delta/states)*(i+1) + emb[1]\n",
        "        x = model.out_linear(state)\n",
        "        x = x.view(-1, 64, 1, 1).cpu().cuda()\n",
        "        x = model.decoder(x)\n",
        "        ax[i+1].imshow(x[0].cpu().data.numpy().reshape((28,28)), interpolation=\"nearest\")\n",
        "        ax[i+1].set_xticks([])\n",
        "        ax[i+1].set_yticks([])\n",
        "        \n",
        "    ax[-1].imshow(x1[0].cpu().data.numpy().reshape((28,28)), interpolation=\"nearest\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fGuHxEK6VEy1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "compute_intermediate_states(net, 10, 20, 20)\n",
        "compute_intermediate_states(net, 30, 40, 20)\n",
        "compute_intermediate_states(net, 50, 60, 20)\n",
        "compute_intermediate_states(net, 70, 80, 20)\n",
        "compute_intermediate_states(net, 90, 100, 20)\n",
        "compute_intermediate_states(net, 110, 120, 20)\n",
        "compute_intermediate_states(net, 130, 140, 20)\n",
        "compute_intermediate_states(net, 150, 160, 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5jGRY6MthELp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Автоэнкодер, убирающий шум"
      ]
    },
    {
      "metadata": {
        "id": "sm5_iDLNbMOI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noisy_net = Autoencoder().cuda()\n",
        "criterion = nn.MSELoss().cuda()\n",
        "optimizer = torch.optim.Adam(noisy_net.parameters(), lr=0.001)\n",
        "\n",
        "loss_acc = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lP_eswKtbKGD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for ep in range(5):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        y = noisy_net(add_noise(data.cuda()))\n",
        "        loss = criterion(y, data.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_acc.append(loss.data[0])\n",
        "        \n",
        "    print('Epoch: ', ep, ', loss: ', float(loss.data[0]), sep='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lRxxrpoofvmk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "compute_one(noisy_net, 1)\n",
        "compute_one(noisy_net, 1, noise=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "958FdeLMdI--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "compute_random(noisy_net, 10, noise=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qatoPFy6imwC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Вариационный автоэнкодер"
      ]
    },
    {
      "metadata": {
        "id": "ocZKnbwOcT8S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvVAE(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ConvVAE, self).__init__()\n",
        "        \n",
        "        self.encoder = nn.Sequential( # 1x28x28 ->\n",
        "            nn.Conv2d(1, 8, 3), # 8x26x26\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Conv2d(8, 16, 3), # 16x24x24\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2), # 16x12x12\n",
        "            \n",
        "            nn.Conv2d(16, 32, 3), # 32x10x10\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2), #32x5x5\n",
        "            \n",
        "            nn.Conv2d(32, 64, 3), # 32x3x3 = 288\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3), # 64x1x1\n",
        "            \n",
        "        )\n",
        "        \n",
        "        self.mu = nn.Linear(64, 2)\n",
        "        self.logvar = nn.Linear(64, 2)\n",
        "        \n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(2, 64, 1, 1),\n",
        "            nn.Upsample(scale_factor=3),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            nn.ConvTranspose2d(32, 16, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            nn.ConvTranspose2d(16, 8, 3),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.ConvTranspose2d(8, 1, 3),\n",
        "            nn.ReLU()\n",
        "            \n",
        "        )\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data = nn.init.xavier_uniform_(m.weight)\n",
        "            \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = Variable(std.data.new(std.size()).normal_())\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(-1, 64)\n",
        "        return self.mu(x), self.logvar(x)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        self.z = z.view(-1, 2, 1, 1)\n",
        "        self.embeding = z.view(-1, 2, 1, 1)\n",
        "        x = self.decoder(self.z)\n",
        "        return x, mu, logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNqeLVpIdBJG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_function(recon_x, x, mu, logvar, batch_size):\n",
        "    BCE = mse_loss(recon_x, x)\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    # Normalise by same number of elements as in reconstruction\n",
        "    KLD /= batch_size * 784.\n",
        "\n",
        "    return BCE + KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eKXWpgs1cxX3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vae_net = ConvVAE().cuda()\n",
        "mse_loss = nn.MSELoss().cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(vae_net.parameters(), lr=0.001)\n",
        "loss_acc = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P6UzUjWQdDxS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for ep in range(20):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        y, mu, logvar = vae_net(data.cuda())\n",
        "        loss = loss_function( y, data.cuda(), mu, logvar, data.size()[0] )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_acc.append(loss.data[0])\n",
        "    \n",
        "    print('Epoch: ', ep, ', loss: ', float(loss.data[0]), sep='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6zgq1dzGesVy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "compute_random(vae_net, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cXrrHc7VlVUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_intermediate_states_vae(model, n1, n2, states):\n",
        "    x1 = train_set[n1][0].cuda()\n",
        "    x1 = x1.view(1, 1, 28, 28).cpu().cuda()\n",
        "    y1 = model(x1)\n",
        "\n",
        "    emb = [model.embeding]\n",
        "\n",
        "    x2 = train_set[n2][0].cpu().cuda()\n",
        "    x2 = x2.view(1, 1, 28, 28)\n",
        "    y2 = model(x2)\n",
        "\n",
        "    emb.append(model.embeding)\n",
        "    \n",
        "    delta = emb[0] - emb[1]\n",
        "    \n",
        "    f,ax = plt.subplots(1, states+2)\n",
        "    \n",
        "    ax[0].imshow(x2[0].cpu().data.numpy().reshape((28,28)), interpolation=\"nearest\")\n",
        "    \n",
        "    for i in range(states):\n",
        "        state = (delta/states)*(i+1) + emb[1]\n",
        "        x = model.decoder(state)\n",
        "        ax[i+1].imshow(x[0].cpu().data.numpy().reshape((28,28)), interpolation=\"nearest\")\n",
        "        ax[i+1].set_xticks([])\n",
        "        ax[i+1].set_yticks([])\n",
        "        \n",
        "    ax[-1].imshow(x1[0].cpu().data.numpy().reshape((28,28)), interpolation=\"nearest\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l_WZjlbPjrXL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "compute_intermediate_states_vae(vae_net, 10, 20, 15)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}